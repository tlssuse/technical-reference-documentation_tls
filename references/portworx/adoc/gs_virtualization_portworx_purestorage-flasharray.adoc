:docinfo:
include::./common_docinfo_vars.adoc[]
include::./gs_virtualization_portworx_purestorage-flasharray-vars.adoc[]
[#art-{article-id}]

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// SUSE Technical Reference Documentation
// Getting Started Guide
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
//
// DOCUMENT ATTRIBUTES AND VARIABLES
//
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// 1. Define variables (document attributes) in the vars file.
// 2. Develop content and reference variables in the adoc file.
// 3. Update the docinfo.xml file as needed.
// 4. Update DC file (at a minimum, deactivate DRAFT mode)
//
// For further guidance, see
//   https://github.com/SUSE/technical-reference-documentation/blob/main/common/templates/start/README.md
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =



= {title}: {subtitle}



== Introduction

As organizations increasingly adopt cloud-native and containerized workloads, the demand for robust, enterprise-grade storage solutions in virtualized environments continues to grow.
{svirt}, powered by Harvester and Kubernetes, delivers a flexible platform for running both virtual machines and modern containerized applications on a unified infrastructure.
To unlock advanced storage features and ensure seamless data management across diverse environments, integrating {pxe} brings unparalleled benefits—ranging from high availability and data protection to hybrid cloud mobility and multi-cluster support.

In this document administrators and platform engineers learn how to deploy, configure, and validate a {svirt} environment with {pxe} and {pfa} Storage, enabling them to deliver resilient, scalable, and efficient storage services for mission-critical workloads in virtualized and cloud-native environments.

This integrated solution addresses a wide range of scenarios, including:

* Application Modernization: Seamlessly migrating or running legacy VM workloads and stateful cloud-native applications on the same infrastructure.
* Hybrid and Multi-Cloud Deployments: Enabling workload and data mobility across on-premises, public cloud, and edge locations.
* Business Continuity and Disaster Recovery: Providing robust backup, granular restore, and cross-site failover for both VMs and containers.
* Dev/Test and Self-Service Environments: Allowing developers to quickly provision persistent, production-grade storage for any workload type.
* Data-Intensive Workloads: Supporting databases, analytics, and AI/ML apps that require high availability and consistent performance.



=== Scope

This document provides comprehensive instructions for installing {pxe} on a {svirt} cluster with a {pfa}.  It details the necessary steps for configuring multipathing, deploying the {pxo} and StorageCluster, and updating {svirt}'s storage configurations.


=== Audience

The intended audience for this guide are system administrators, platform engineers, DevOps engineers, and IT professionals responsible for designing, deploying, managing, and maintaining a modern infrastructure environment for container and virtual machine workloads.  A basic understanding of Kubernetes and storage concepts is assumed.



== Overview
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Detail the steps of the installation procedure.
// Replace 'Procedure' with one or more appropriate sections, such as:
// - 'Setting up the environment'
// - 'Installing the components'
// - 'Configuring and tuning'
// - 'Validating the deployment'
// You may find it useful to organize complex procedures into
// subsections.
//
// - As appropriate, make use of:
//   - Ordered lists for steps
//   - Code blocks for source code and console commands
//     Readers should be able to use copy and paste to leverage
//     commands and code in their environments
//   - Listing blocks for output
//   - Screenshots and diagrams
//   - Admonitions (notes, tips, warnings, etc.)
//
// NOTE: Always include some validation or verification in your guide.
//
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This practical guide illustrates how SUSE Virtualization can leverage a Pure Storage FlashArray to provide a robust, persistent, block storage for virtual machine and container workloads.  The environment is illustrated in the diagram below, showing a highly available, three-node SUSE Virtualization cluster connected to the Pure Storage FlashArray through a dedicated storage network.

image::suse-virt_portworx_purestorage-flasharray_2400x1800.png[title="Architecture Diagram: SUSE Virtualization with Portworx and Pure Storage FlashArray", scaledwidth="90%", align="center"]


{empty} +
Key components of this architecture are:

{svirt}::
{svirt-website}[{svirt}] (formerly Harvester) is a modern, open, interoperable, hyperconverged infrastructure (HCI) solution built on Kubernetes.  {svirt} leverages other components (such as {slmicro-website}[{slmicro}] and {rke2-docs}[{rke2}]) to deliver a secure, resilient, and scalable platform for managing virtual machine and container workloads.
Access the {svirt-docs-intro}[{svirt} documentation] for detailed technical information, including {svirt-docs-reqs}[Hardware and Network Requirements] and installation guidance.  This guide references {svirt} {svirt-version1} and later.


{pxe} and {pxo}::
{pxe-website}[{pxe}] delivers elastic scalability, industry-leading availability, and self-service access to any storage infrastructure for the most widely used Kubernetes distribution.
This fully-integrated storage solution offers automated capacity management, thin provisioning, and flexibility across hybrid, multi-cloud, and on-premises deployments.
{pxe} installation, configuration, and updates are handled through the {pxo}.
This guide references {pxe-docs}[{pxe}] {pxe-version1}} or later and {pxo} {pxo-version1} or later.


{pfa-long}::
{pfa-website}[{pfa}] delivers high-performance, scalable, all-flash storage.
Your {pfa} must be configured to meet the {pxe-reqs}[{pxe} environment prerequisites] and be accessible from the {svirt} cluster nodes.

{empty} +
{empty}

In the following pages, you will learn how to configure your {svirt} environment to leverage a {pfa} for virtual machine storage.
This includes:

* Preparing the {svirt} cluster nodes and the {pfa}
* Deploying the {pxo} to install and configuring {pxe}
* Defining the Portworx StorageClass
* Creating a virtual machine with {pfa} persistent storage



== Prepare the environment

Before starting the installation, perform the following preparatory steps:

. Enable multipath support on the {svirt} cluster nodes.

.. Create a Harvester CloudInit resource file to deploy the required node-level configuration with the following contents:
+
[source, yaml]
----
apiVersion: node.harvesterhci.io/v1beta1
kind: CloudInit
metadata:
  name: pure-multipath
spec:
  contents: |
    stages:
      network:
      - name: "Configure pure storage"
        files:
        - path: /etc/udev/rules.d/99-pure-storage.rules
          permissions: 0644
          content: |
            #ACTION=="change", SUBSYSTEM=="scsi", ENV{SDEV_UA}=="INQUIRY_DATA_HAS_CHANGED", TEST=="rescan", ATTR{rescan}="x"
            ACTION=="change", SUBSYSTEM=="scsi", ENV{SDEV_UA}=="CAPACITY_DATA_HAS_CHANGED", TEST=="rescan", ATTR{rescan}="x"
            #ACTION=="change", SUBSYSTEM=="scsi", ENV{SDEV_UA}=="THIN_PROVISIONING_SOFT_THRESHOLD_REACHED", TEST=="rescan", ATTR{rescan}="x"
            #ACTION=="change", SUBSYSTEM=="scsi", ENV{SDEV_UA}=="MODE_PARAMETERS_CHANGED", TEST=="rescan", ATTR{rescan}="x"
            ACTION=="change", SUBSYSTEM=="scsi", ENV{SDEV_UA}=="REPORTED_LUNS_DATA_HAS_CHANGED", RUN+="scan-scsi-target $env{DEVPATH}"
        - path: /etc/multipath.conf
          content: |
            defaults {
              user_friendly_names no
              enable_foreign "^$"
                    polling_interval    10
            }
            devices {
                device {
                    vendor                      "NVME"
                    product                     "Pure Storage FlashArray"
                    path_selector               "queue-length 0"
                    path_grouping_policy        group_by_prio
                    prio                        ana
                    failback                    immediate
                    fast_io_fail_tmo            10
                    user_friendly_names         no
                    no_path_retry               0
                    features                    0
                    dev_loss_tmo                60
                }
                device {
                    vendor                   "PURE"
                    product                  "FlashArray"
                    path_selector            "service-time 0"
                    hardware_handler         "1 alua"
                    path_grouping_policy     group_by_prio
                    prio                     alua
                    failback                 immediate
                    path_checker             tur
                    fast_io_fail_tmo         10
                    user_friendly_names      no
                    no_path_retry            0
                    features                 0
                    dev_loss_tmo             600
                }
            }
            blacklist_exceptions {
                    property "(SCSI_IDENT_|ID_WWN)"
            }
            blacklist {
                  devnode "^pxd[0-9]*"
                  devnode "^pxd*"
                  device {
                    vendor "VMware"
                    product "Virtual disk"
                  }
            }
          permissions: 0644
      - name: "Start multipathd service"
        systemctl:
          enable:
          - multipathd
          start:
          - multipathd
  filename: 99_multipathd.yaml
  matchSelector: {}

----

.. Apply the CloudInit resource resource to the {svirt} cluster.
+
[source, console]
----
kubectl apply -f pure-multipath.yaml
----

.. Restart the {svirt} cluster nodes.


. {pxe-flasharray-user-access}[Configure user access] in the Pure Storage FlashArray.


. {pxe-k8s-secret}[Create a Kubernetes secret], named `px-pure-secret`, to securely store your {pfa} credentials.

.. Create a file, named `pure.json`, containing your {pfa} credentials.

.. Add the secret to your `portworx` namespace.
+
[source, console]
----
kubectl create secret generic px-pure-secret --namespace portworx --from-file=pure.json
----


== Generate the Portworx spec

The {pxo} is designed to efficiently manage the installation and upgrade workflow of all {pxe} components, but it must be configured for your environment.
This is accomplished by generating a Portworx spec.

. Log in to {pxe-central}[Portworx Central].

. Select *Portworx Enterprise* -> *Generate Spec*.

. Choose the *Portworx Version* and `Pure FlashArray` for *Platform*, then click *Customize*.

. On the *Basic* tab:
+
image::suse-portworx-modvirt_px-spec_01_basic.png[title="Portworx: Generate Spec - Basic", scaledwidth="90%", align="center"]

.. Validate or fill in values for each of the following fields:
+
--
* *Portworx Version*
* *Kubernetes Version*
* *Namespace* (for example, `portworx`)
--

.. Select the `Built-in` option for *etcd*.

.. Click *Next*.



. On the *Storage* tab, make the following choices:
+
image::suse-portworx-modvirt_px-spec_02_storage.png[title="Portworx: Generate Spec - Storage", scaledwidth="90%", align="center"]

.. Set *Select Cloud Platform* to `Pure FlashArray`.
.. Set *Select type of disk* to `Create Using a Spec`
.. Enable PX-StoreV2.
.. Select `Fiber Channel` for *Type of  storage area network*.
.. Enter the desired *Size* of the disk to be mapped to the SUSE Virtualization cluster.
.. Update the *Max storage nodes per availability zone* to `3` (for your 3-node cluster).
.. Click *Next*.

. On the *Network* tab, configure the Portworx service port, then click *Next*.
//
+
Note that the default port is `9001`.
+
image::suse-portworx-modvirt_px-spec_03_network.png[title="Portworx: Generate Spec - Network", scaledwidth="90%", align="center"]

. On the *Customize* tab, select `Rancher Kubernetes Engine (RKE)` then click *Finish*.
+
image::suse-portworx-modvirt_px-spec_04_customize.png[title="Portworx: Generate Spec - Customize", scaledwidth="90%", align="center"]

. You are next presented with two Kubectl commands.
The first is for deploying the {pxo}, and the second is for deploying the Portworx StorageCluster.
Save these commands, as you will need them in the following section.



== Deploy the {pxo} and Portworx StorageCluster

The {pxo} efficiently manages the installation and upgrade workflow of all {pxe} components.
To deploy the {pxo}, you use the first of the Kubectl commands you generated in <<Generate the Portworx spec>> as detailed below.

. Log in to the SUSE Virtualization management node command-line interface (CLI) with root access.

. Run the first Kubectl command saved from the previous section to install the {pxo}.
//
+
The command should look something like:
+
[source, console]
----
kubectl apply -f 'https://install.portworx.com/3.3?comp=pxoperator&kbver=1.3.0&ns=portworx'
----
+
This should result in output like:
+
[source, console]
----
namespace/portworx created
serviceaccount/portworx-operator created
clusterrole.rbac.authorization.k8s.io/portworx-operator created
clusterrolebinding.rbac.authorization.k8s.io/portworx-operator created
deployment.apps/portworx-operator created
----

. If you are using {svirt} v1.6.0 or later, add a Stork Snapshot StorageClass.

.. Create the YAML file, `stork-snapshot-sc.yaml`, with the following contents:
+
[source, yaml]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: stork-snapshot-sc
  annotations:
cdi.harvesterhci.io/storageProfileVolumeModeAccessModes: '{"Block":["ReadWriteOnce"]}'
provisioner: stork-snapshot
allowVolumeExpansion: true
reclaimPolicy: Delete
volumeBindingMode: Immediate
----

.. Apply the the YAML file to add the Stork Snapshot StorageClass.
+
[source, console]
----
kubectl apply -f stork-snapshot-sc.yaml
----
+
You should see this output:
+
[source, console]
----
storageclass.storage.k8s.io/stork-snapshot-sc created
----

. Execute the second of the Portworx spec Kubectl commands you generated in <<Generate the Portworx spec>> to deploy the Portworx StorageCluster.
//
+
The command should look something like:
+
[source, console]
----
kubectl apply -f 'https://install.portworx.com/3.3?operator=true&mc=false&kbver=1.3.0&ns=portworx&b=true&iop=6&mz=3&s=%22size%3D1000%22&pureSanType=FC&ce=pure&dmthin=true&c=px-cluster-82af5d7d-f249-4f45-9e80-d1590e7bfce4&stork=true&csi=true&mon=true&tel=true&st=k8s&promop=true'
----
+
If successful, you will see output like:
+
[source, console]
----
storagecluster.core.libopenstorage.org/px-cluster-82af5d7d-f249-4f45-9e80-d1590e7bfce4 created
----



== Add the Portworx StorageClass

. Ensure you are still logged in to the SUSE Virtualization management CLI as root.

. Create the YAML file, `portworx-storageclass.yaml`, with the following contents:
+
[source, yaml]
----
allowVolumeExpansion: true
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
  name: data-disk-storage
parameters:
  cdi.kubevirt.io/storage.contentType: kubevirt
  nodiscard: "true"
  repl: "2"
provisioner: pxd.portworx.com
reclaimPolicy: Delete
volumeBindingMode: Immediate
----

. Apply this YAML file to create add the Portworx StorageClass.
+
[source, console]
----
kubectl apply -f portworx-storageclass.yaml
----
+
You should see:
+
[source, console]
----
storageclass.storage.k8s.io/data-disk-storage created
----

[TIP]
====
You may see a “request is invalid” error, such as:
[source, console]
----
The request is invalid: default StorageClass, 'harvester-longhorn', already exists.
Please reset it first before setting 'data-disk-storage' as default.
----

If this happens:

. Unset the default `harvester-longhorn` StorageClass using the command:
+
[source, console]
----
kubectl patch storageclass harvester-longhorn -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
----

. Re-apply the Portworx StorageClass.
+
[source, console]
----
kubectl apply -f portworx-storageclass.yaml
----
====


== Update the Portworx CSI driver configuration


. Log in to the SUSE Virtualization UI.

. Navigate to *Advanced* > *Settings*.

. Locate `csi-driver-config` and select *⋮* > *Edit Setting*.

. Set the *Provisioner* to `pxd.portworx.com`.

. Set the *Volume Snapshot Class Name* to `px-csi-snapclass`.
//
+
This setting points to the name of the VolumeSnapshotClass used for creating volume snapshots or VM snapshots.

image::suse-portworx-modvirt_csi-driver-config-external.png[title="SUSE Virtualization: csi-driver-config", scaledwidth="90%", align="center"]



== Validate the integration

Ensure that {pxe} is correctly integrated with {svirt} by verifying that a virtual machine (VM) can be provisioned with storage on the {pfa}.

. Create a VM with Portworx-provisioned storage.
//
+
For guidance, refer to the {svirt-docs-create-vm}[SUSE Virtualization: Create a Virtual Machine].
//
Be sure to select the StorageClass provisioned by Portworx (`data-disk-storage`) for your VM disk volume.

. When your VM is ready, verify that the VM is backed by Pure Storage with the Portworx CSI.
//
+
You can use the {svirt} UI or CLI to verify this.

.. Verify in the UI.
+
[NOTE]
====
Editor: Add image
====

... In the {svirt} UI, navigate to *Virtual Machines* > <Your VM> > *Volumes*.

... Confirm that the attached disk is the `data-disk-storage` StorageClass.



.. Verify in the CLI.

... Log in to the SUSE Virtualization management CLI.

... List the PersistentVolumeClaims (PVCs) in the VM’s namespace.
+
[source, console]
----
kubectl get pvc -n <namespace>
----
+
[source, console]
----
NAME          STATUS  VOLUME                                    CAPACITY  ACCESS MODES  STORAGECLASS       AGE
vm1-rootdisk  Bound   pvc-8f3c8b2c-6e1e-4c6a-a83e-9d6c34ac3b21  40Gi      RWX           data-disk-storage  2m
----

... Confirm that the STORAGECLASS column shows `data-disk-storage`.
//
+
This indicates that the volume is using the StorageClass created earlier.

... Confirm that the volume is provisioned by 'pxd.portworx.com'.
+
[source, console]
----
kubectl describe pv pvc-8f3c8b2c-6e1e-4c6a-a83e-9d6c34ac3b21
----
+
[source, console]
----
Name:                 pvc-8f3c8b2c-6e1e-4c6a-a83e-9d6c34ac3b21
StorageClass:         data-disk-storage
Annotations:
pv.kubernetes.io/provisioned-by: pxd.portworx.com
Status: Bound
Reclaim Policy:       Delete
VolumeMode:           Block
Source:
    Type:             CSI (a Container Storage Interface (CSI) volume source)
    Driver:           pxd.portworx.com
    FSType:
    VolumeHandle:     424582431912071110
   ReadOnly:          false
   VolumeAttributes:  attached=ATTACH_STATE_EXTERNAL
                      error=
                      parent=
                      readonly=false
                      secure=false
                      shared=false
                      shared_mode=BLOCK
                      sharedv4=false
                      state=VOLUME_STATE_DETACHED
                      type=px-raw-volume
----


With these confirmations, you have verified that your VM is backed by the {pfa} with {pxe}.



== Summary

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Summarize:
// - Solution description
// - Motivation for the guide
// - What was done
// - Suggested next steps for the learning journey
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

Organizations are modernizing their applications and infrastructure, transitioning from traditional, virtual machine deployments to modern, cloud-native technologies, such as containers and Kubernetes.  SUSE Virtualization provides a flexible platform that enables container and virtual machine workloads to run side-by-side, on the same, unified infrastructure.  Portworx Enterprise by Pure Storage brings resilient, scalable, and efficient storage services for mission-critical workloads, supporting enterprise availability, mobility, and data protection needs.  Together, SUSE Virtualization and Portworx by Pure Storage present enterprises with a robust, flexible infrastructure platform to support their mission-critical, virtualized and cloud-native workloads.

This guide provides an overview of this unified, infrastructure platform along with detailed steps for  configuring and validating the integration of SUSE Virtualization with Portworx Enterprise and a Pure Storage FlashArray to deliver a unified, infrastructure platform.


Continue your learning journey by exploring the following technical resources:
* {svirt-docs-intro}[SUSE Virtualization documentation]
* {pxe-manage-rwx-block}[Manage Portworx RWX Block Volumes on SUSE Virtualization]
* {pfa-docs}[Pure Storage FlashArray]





// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Do not modify below this break.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

++++
<?pdfpagebreak?>
++++


:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
